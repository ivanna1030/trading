{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb065a3",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "11/09/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a88e5",
   "metadata": {},
   "source": [
    "Optimization:\n",
    "\n",
    "- In a broad sense, is the process of making something as effective or functional as possible. Whether you're allocating resources, minimizing costs, or maximizing profits, optimization is the key to finding the best solution to a problem.\n",
    "\n",
    "Types of Optimization Problems P1:\n",
    "\n",
    "- Linear Optimization: In linear optimization problems, both the objective function and constraints are linear. This simplicity allows for efficient solutions and is quite easy to optimize.\n",
    "\n",
    "- Nonlinear Optimization: Nonlinear optimization problems involve nonlinear relationships in either the objective function, constraints, or both. These are more complex and may require specialized algorithms to find optimal solutions.\n",
    "\n",
    "Types of Optimization Problems P2:\n",
    "\n",
    "- Continuous Optimization: In continuous optimization, decision variables can take any real value within a specified range. This is common in scenarios where solutions can exist as any point along a continuum.\n",
    "\n",
    "- Discrete Optimization: Discrete optimization deals with problems where decision variables must take on distinct, separate values. This is prevalent in scenarios like integer programming, where solutions must be whole numbers.\n",
    "\n",
    "Types of Optimization Problems P3:\n",
    "\n",
    "- Single-Objective Optimization: In single-objective optimization, we aim to either maximize or minimize a single goal or criterion. This is common when decisions are primarily driven by a singular objective.\n",
    "\n",
    "- Multi-Objective Optimization: Multi-objective optimization involves optimizing multiple conflicting objectives simultaneously. This introduces the challenge of finding a trade-off between different goals.\n",
    "\n",
    "Objective Function:\n",
    "\n",
    "- The objective function is a mathematical expression that encapsulates the goal of our optimization problem, it consists of decision variables and coefficients.\n",
    "\n",
    "- Decision variables are the elements we can adjust to achieve our goal, while coefficients represent the impact each variable has on the objective.\n",
    "\n",
    "Notation:\n",
    "\n",
    "- $min. f(x)$\n",
    "\n",
    "- $s.t. \\quad{x} \\in \\Omega$,\n",
    "\n",
    "    - where f is a scalar-based fupction (objective function), x is the decision variable, and $\\Omega$ is the constraint set (feasible set).\n",
    "\n",
    "Optimal Solution:\n",
    "\n",
    "- An optimal solution $x^*$ is a point in $\\Omega$ that satisfies:\n",
    "\n",
    "    - $f(x^*) \\leq f(x), \\forall x \\in \\Omega$\n",
    "\n",
    "Scipy's minimize:\n",
    "\n",
    "- The minimize function provides a common interface to unconstrained and constrained minimization algorithms for multivariate scalar functions in scipy optimize.\n",
    "\n",
    "Unbounded Optimization Methods P.1:\n",
    "\n",
    "- CG: The idea of the CG method is to pick n orthogonal search directions first and, in each search direction, take exactly one step such that the step size is to the proposed solution x at that direction. The solution is reached after n steps as the number of iterations needed by the CG method is equal to the number of different eigenvalues of A. This makes it attractive for large and sparse problems. The method can also be generalized to a minimization method for general smooth functions.\n",
    "\n",
    "- BFGS: In order to converge more quickly to the solution, this routine uses the gradient of the objective function. If the gradient is not given by the user, then it is estimated using first-differences. The Broyden-Fletcher-Goldfarb-Shanno (BFGS) method typically requires fewer function calls than the simplex algorithm even when the gradient must be estimated.\n",
    "\n",
    "Unbounded Optimization Methods P.2:\n",
    "\n",
    "- Newton-CG: Newton-Conjugate Gradient algorithm is a modified Newton's method and uses a conjugate gradient algorithm to (approximately) invert the local Hessian. The inverse of the Hessian is evaluated using the conjugate-gradient method. This method can be inefficient when the Hessian is ill-conditioned because of the poor quality search directions provided.\n",
    "\n",
    "Bounded Optimization Methods P.1:\n",
    "\n",
    "- Nelder-Mead: The simplex algorithm is probably the simplest way to minimize a fairly well-behaved function. It requires only function evaluations and is a good choice for simple minimization problems. However, because it does not use any gradient evaluations, it may take longer to find the minimum.\n",
    "\n",
    "- Powell: Powell's conjugate direction method is an algorithm for finding a local minimum of a function. It is useful for calculating the local minimum of a continuous but complex function, especially one without an underlying mathematical definition, because it is not necessary to take derivatives.\n",
    "\n",
    "Bounded Optimization Methods P.2:\n",
    "\n",
    "- L-BFGS- B: Limited-memory BFGS Bounded is an optimization algorithm that approximates the BFGS algorithm using a limited amount of computer memory. The method works by identifying fixed and free variables at every step (using a simple gradient method), and then using the L-BFGS method on the free variables only to get higher accuracy, and then repeating the process. This is particularly suited to problems with very large numbers of variables (>1000).\n",
    "\n",
    "- TNC: The truncated Newton method is a Hessian-free optimization algorithm designed for optimizing nonlinear functions with large numbers of independent variables. A TNC method consists of repeated application of an iterative optimization algorithm to approximately solve Newton's equations, to determine an update to the function's parameters.\n",
    "\n",
    "Constrained & Bounded Optimization Methods:\n",
    "\n",
    "- COBYLA: Constrained optimization by linear approximation is a numerical optimization method for constrained problems where the derivative of the objective function is not known. It works by iteratively approximating the actual constrained optimization problem with linear programming problems.\n",
    "\n",
    "- SLSQP: SLSQP minimizes a function of several variables with any combination of bounds, equality and inequality (linear or nonlinear) constraints. It is ideal for mathematical problems for which the objective function and the constraints are twice continuously differentiable, but not necessarily convex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb87ab",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd974741",
   "metadata": {},
   "source": [
    "Fine tuning is crucial because the default settings of machine learning models may not always yield optimal results for a specific task or dataset. It's about going beyond the basics to extract the maximum potential from our models.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Learning Rate\n",
    "\n",
    "- L1, L2 regularization\n",
    "\n",
    "- Train-test ration\n",
    "\n",
    "- Batch size\n",
    "\n",
    "- Kernel (rbf, sigmoid,...)\n",
    "\n",
    "- Number of categories/groups\n",
    "\n",
    "- Solver (Ibfgs, newton-cg,...)\n",
    "\n",
    "- Polynomial Degree\n",
    "\n",
    "- K folds\n",
    "\n",
    "- Split criterion (gini, entropy,..)\n",
    "\n",
    "- Number of hidden layers\n",
    "\n",
    "- Number of neurons per layer\n",
    "\n",
    "- Optimizer (Adam, sgd,...)\n",
    "\n",
    "- Activation fun (sigmoid, relu,...)\n",
    "\n",
    "- Cost function (cross-entropy, rmse,...)\n",
    "\n",
    "- Dropout rate\n",
    "\n",
    "- Epochs\n",
    "\n",
    "- Pool size\n",
    "\n",
    "- Filters\n",
    "\n",
    "- Kernel Size\n",
    "\n",
    "Grid Search:\n",
    "\n",
    "- The traditional way of performing hyperparameter optimization has been grid search, or a parameter sweep, which is simply an exhaustive searching through a manually specified subset of the hyperparameter space of a learning algorithm.\n",
    "\n",
    "- Since the parameter space of a machine learner may include real-valued or unbounded value spaces for certain parameters, manually set bounds and discretization may be necessary before applying grid search.\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Definitely returns an optimal configuration for the given space, but that might not be a global optima.\n",
    "\n",
    "- Can easily be parallelized since each evaluation is independent.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- You must define the search space properly.\n",
    "\n",
    "- Exhaustive search means it evals all possible combinations (cartesian prod).\n",
    "\n",
    "Bayesian Optimization (Tree Parzen Estimator):\n",
    "\n",
    "- It keeps track of past evaluation results and builds a probability model of the objective function where it selects the most promising hyperparameters to evaluate in the true objective function.\n",
    "\n",
    "- TPE models P(score | hyperparams) and P(hyperparams). The TPE models P(s|h) by transforming that generative process, replacing the distributions of the configuration prior with non-parametric densities."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
